{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 4 - Regressão Logística\n",
    "\n",
    "Na aula de hoje, vamos explorar os seguintes tópicos em Python:\n",
    "\n",
    "- 1) Introdução\n",
    "- 2) Regressão logística\n",
    "- 4) Métricas de performance para problemas de classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Introdução\n",
    "\n",
    "**Problemas de classificação** são aqueles em que queremos determinar a que **categoria ou classe** dentro de um **conjunto discreto de classes** uma dada observação pertence, com base em suas features.\n",
    "\n",
    "Para isso, construímos um **classificador**: modelo que tem como input as features (contínuas ou discretas) e como output uma entre as classes (discretas).\n",
    "\n",
    "> Principal diferença entre problemas de regressão e classificação:\n",
    "> - Regressão: valores contínuos;\n",
    "> - Classificação: valores (classes) discretas (binárias ou não).\n",
    "\n",
    "No caso de regressão, a hipótese será a equação que determina o target diretamente;\n",
    "\n",
    "No caso de classificação, a hipótese tem o objetivo de **separar as diferentes classes**. Por isso, muitas vezes utilizamos o termo **fonteira de classificação**, ou **fronteira de decisão**. De um lado da fronteira, temos uma classe; do outro, a outra classe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i0.wp.com/vinodsblog.com/wp-content/uploads/2018/11/Classification-vs-Regression.png?fit=2048%2C1158&ssl=1\" width=700>\n",
    "\n",
    "<img src=\"https://i.pinimg.com/originals/71/8e/6a/718e6a40e1782bead960e58d3c52663b.png\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problemas de classificação são comumente divididos com relação ao **número de classes** a serem preditas (isto é, com relação à estrutura do espaço de target):\n",
    "\n",
    "- Classificação binária: duas classes (0 e 1);\n",
    "- Classificação multiclasse: $n$ classes (0, 1, ..., $n-1$), com $n > 2 \\in \\mathbb{N}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplos de problemas de classificação:\n",
    "- Detecção de e-mails SPAM: um e-mail é SPAM ou não?;\n",
    "    - Features: palavras contidas no corpo do e-mail; remetente; assunto;\n",
    "- Detecção de doenças: que codição médica a pessoa tem?\n",
    "    - Features: sintomas fisiológicos; resultados de exames (medidas de variáveis biológicas);\n",
    "- Detecção do tipo de documento: secreto, confidencial ou não-sensível?\n",
    "    - Features: palavras no corpo do texto; título;\n",
    "- Detecção de fraudes de cartão de crédito: uma operação é fraudulenta ou não?;\n",
    "    - Features: histórico de transações; hora, local e frequência das transações; tipo de compra;\n",
    "- Modelo de risco de crédito: qual é a chance de determinada pessoa não pagar seu empréstimo?\n",
    "    - Features: histórico de pagamento; score de crédito;\n",
    "    \n",
    "    \n",
    "<img src=\"https://developers.google.com/machine-learning/guides/text-classification/images/TextClassificationExample.png\" width=500>\n",
    "\n",
    "\n",
    "\n",
    "Veremos hoje um dos mais simples e importantes classificadores: a **Regressão Logística!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de conhecermos o método, vamos dar uma rápida olhada na base qual a qual trabalharemos hoje!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________\n",
    "\n",
    "Para introduzirmos as ideias, utilizaremos um dataset de marketing (propagandas/advertising), que está disponível no <a href=\"https://www.kaggle.com/fayomi/advertising\">Kaggle</a>. Este é um dataset artificial e didático, com os dados bem separáveis, o que é ótimo para ilustração!<br>\n",
    "\n",
    "Visite o Kaggle e procure por \"advertising\" para datasets relacionados reais e ainda mais interessantes\n",
    "\n",
    "A base que utilizaremos contém as seguintes colunas:\n",
    "\n",
    "* 'Daily Time Spent on Site': tempo que o cliente ficou no site (em minutos);\n",
    "* 'Age': idade do cliente (em anos);\n",
    "* 'Area Income': média salarial (por ano) da região geográfica do cliente;\n",
    "* 'Daily Internet Usage': tempo médio (em minutos) que o cliente fica na internet;\n",
    "* 'Ad Topic Line': título do anúncio;\n",
    "* 'City': cidade do cliente;\n",
    "* 'Male': dummy indicando se o cliente é do sexo masculino (1) ou não (0);\n",
    "* 'Country': país do cliente;\n",
    "* 'Timestamp': marcação de tempo em que o cliente clickou no anúncio OU fechou a página\n",
    "* 'Clicked on Ad': dummy indicando se o cliente clickou no anúncio (1) ou não (0).\n",
    "\n",
    "Nosso objetivo é criar um modelo que possa prever se um determinado usuário clickará em um anúncio online ou não, com base em suas características pessoais/comportamentais, bem como informações relativas ao anúncio.\n",
    "\n",
    "Tomamos como variáveis independentes (preditores/features) as primeiras 9 colunas, enquanto nossa variável dependente (target) é a última coluna (\"Clicked on Ad\").\n",
    "\n",
    "Ou seja, nosso modelo deve ser capaz de dizer se um usuário com um conjunto particular das 9 features clickará no anúncio ou não. \n",
    "\n",
    "__IMPORTANTE!__\n",
    "\n",
    "Pense no problema de negócio que estamos querendo resolver com nosso modelo -- direcionamento de marketing! Temos os dados dos nossos clientes (customer-centric), nós os conhecemos! Não podemos utilizar essa informação a nosso favor?\n",
    "\n",
    "Talvez não faça sentido exibir o anúncio para um usuário que tem baixa probabilidade de clickar no ad, não é mesmo? \n",
    "\n",
    "Por outro lado, é muito mais eficiente direcionar nosso marketing aos clientes com alta chance de clickar no nosso anúncio!\n",
    "\n",
    "Assim, economizamos dinheiro (todo anúncio é pago!), e ganhamos em eficiência e alcance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:47:43.385536Z",
     "start_time": "2022-05-02T21:47:39.929120Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código abaixo é apenas para formatar os números em até 3 casas decimais. \n",
    "\n",
    "Fica aqui pra conhecimento e também pq vai nos auxiliar a ver melhor as probabilidades no final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:47:43.400525Z",
     "start_time": "2022-05-02T21:47:43.388532Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T01:37:58.731197Z",
     "start_time": "2020-02-14T01:37:58.711810Z"
    }
   },
   "source": [
    "Vamos ler a base!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:47:43.734335Z",
     "start_time": "2022-05-02T21:47:43.407524Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../datasets/advertising.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:47:43.781309Z",
     "start_time": "2022-05-02T21:47:43.739332Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:47:43.970200Z",
     "start_time": "2022-05-02T21:47:43.785306Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:47:44.080142Z",
     "start_time": "2022-05-02T21:47:43.974200Z"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:47:44.142103Z",
     "start_time": "2022-05-02T21:47:44.083136Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"Clicked on Ad\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: EDA em casa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-25T16:34:38.677859Z",
     "start_time": "2022-04-25T16:34:37.313127Z"
    }
   },
   "source": [
    "__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que conhecemos brevemente o problema, vamos conhecer o método de modelagem!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Nossa discussão será feita toda em cima do problema de **classificação binária**, ou seja, com o espaço de target $\\mathcal{Y} = \\{0, 1\\}$ (as labels 0 e 1 são arbitrárias, e simplesmente diferenciam os dois valores possíveis para o target. Uma outra codificação comum é $\\mathcal{Y} = \\{-1, +1\\}$)\n",
    "\n",
    "Para o caso multiclasse, há algumas anterações nos fundamentos dos métodos, mas, na prática, a implementação será direta, então não precisamos nos preocupar!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Regressão Logística\n",
    "\n",
    "A [Regressão Logística](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) (também chamado de **logit**), apesar do nome, é um método que aplicaremos a problemas de classificação!\n",
    "\n",
    "O objetivo da regressão logística é: **modelar a probabilidade $P(\\vec{x})$ de dada observação (com features $\\vec{x}$) pertencer a uma das classes (que comumente chamamos de classe 1)**, ou seja, queremos modelar:\n",
    "\n",
    "$$ P( y = 1 | \\vec{x}) $$\n",
    "\n",
    "Naturalmente, $0 \\le P(\\vec{x}) \\le 1$. \n",
    "\n",
    "> Lembre-se que: $ P( y = 0 | \\vec{x}) = 1 - P( y = 1 | \\vec{x}) $\n",
    "\n",
    "Uma vez que tivermos uma função que modele a probabilidade acima, podemos tomar a decisão de classificação da seguinte maneira:\n",
    "\n",
    "- $P(\\vec{x}) \\ge 0,5$: x pertence à classe 1\n",
    "- $P(\\vec{x}) < 0.5$: x pertence à classe 0\n",
    "\n",
    "Obs.: este valor de 0.5 (50%) é chamado de \"cutoff\", e pode ser ajustado, embora o default fixá-lo em 50%!\n",
    "\n",
    "> É justamente através do cutoff que tomamos uma decisão discreta (classificação) a partir de um método de regressão!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poderíamos pensar em utilizar a regressão linear em nossos problemas de classificação, mas isso não é uma boa ideia: acabamos encontrando probabilidades negativas e fit ruim!\n",
    "\n",
    "No exemplo a seguir, temos a probabilidade de não-pagamento (default) de um empréstimo com base em uma feature (balanço). Note probabilidades negativas!\n",
    "\n",
    "<figure>\n",
    "    <img src=\"https://s3-sa-east-1.amazonaws.com/lcpi/70189f79-2886-4e59-893b-1dac9dd64078.png\" height=\"400\" width=\"400\">\n",
    "</figure> \n",
    "\n",
    "Para resolver este problema, podemos adaptar a função de regressão linear para uma função que tem imagem entre 0 e 1. Seria legal se tivéssemos algo como:\n",
    "\n",
    "<figure>\n",
    "    <img src=\"https://s3-sa-east-1.amazonaws.com/lcpi/6d54529a-d295-47a3-8a11-1f426fde7229.png\" height=\"400\" width=\"400\">\n",
    "</figure> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um exemplo de tal função é a **função logística** ou **função sigmoidal**:\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/970/1*Xu7B5y9gp0iL5ooBj7LtWw.png\" width=400>\n",
    "\n",
    "Note que:\n",
    "\n",
    "- $z \\in \\mathbb{R}$\n",
    "- $0 \\le \\phi(z) \\le 1$\n",
    "\n",
    "Para incorporar a ideia da regressão linear na regressão logística, tomamos:\n",
    "\n",
    "- $z = b_0 + b_1x$, que é o modelo de regressão linear (uma variável);\n",
    "\n",
    "E substituímos na função logística:\n",
    "\n",
    "- $\\phi(x) = \\frac{1}{1 + e^{-(b_0 + b_1 x)}}$\n",
    "\n",
    "Com isso, tomamos qualquer output real do modelo linear e transformamos em um valor entre 0 e 1, como queríamos!\n",
    "\n",
    "<img src=\"https://s3-sa-east-1.amazonaws.com/lcpi/e5ecf372-6790-49db-9bad-95bc4b19df27.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No nosso caso, como queremos modelar probabilidades, a função acima é exatamente a **hipótese** do estimador de regressão logística! Isto é,\n",
    "\n",
    "$$f_{H, \\vec{b}}(x) = P(x) = \\frac{1}{1 + e^{-(b_0 + b_1 x)}}$$\n",
    "\n",
    "Ou, para a regressão logística múltipla com $p$ features $\\vec{x} = x_1, \\cdots, x_p$:\n",
    "\n",
    "$$f_{H, \\vec{b}}(\\vec{x}) = P(\\vec{x}) = \\frac{1}{1 + e^{-(b_0 + b_1 x_1 + \\cdots + b_p x_p)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No fim, temos que a predição é tomada em termos do cutoff $\\alpha$, e, com isso, chegamos no $\\hat{y}$:\n",
    "\n",
    "$$\\hat{y} = \\left\\{\\begin{matrix}\n",
    "1, \\text{se } P(\\vec{x}) \\geq \\alpha\\\\  \n",
    "0, \\text{se } P(\\vec{x}) < \\alpha\n",
    "\\end{matrix}\\right.$$\n",
    "\n",
    "Note, portanto, que apesar da hipótese ser uma função não linear, **a fronteira de decisão** é linear, sendo definida pela função por partes acima, com base no cutoff e na probabilidade!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com um pouco de álgebra, é possível mostrar que: \n",
    "\n",
    "$ b_0 + b_1 x_1 + \\cdots + b_p x_p = \\log \\left ( \\frac{P}{1-P} \\right ) $\n",
    "\n",
    "A quantidade $\\frac{P}{1-P}$ é conhecida como **odds/chance**; e $\\log \\left ( \\frac{P}{1-P} \\right )$ é o [log-odds ou logit](https://en.wikipedia.org/wiki/Logit).\n",
    "\n",
    "Note, portanto, que podemos entender a regressão logística como um modelo em que **o logit é linear com as features**. \n",
    "\n",
    "> Portanto, esse fato e o anterior fazem com que, de fato, a regressão logística seja um **um modelo linear**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na regressão logística, nosso conjunto de hipóteses é: $\\mathcal{H} = \\left \\{ \\frac{1}{1 + e^{-(b_0 + b_1 x_1 + \\cdots + b_p x_p)}} \\right \\}$.\n",
    "\n",
    "O objetivo do algoritmo de aprendizagem será, como sempre, determinar qual é o vetor de parâmetros $\\vec{b}$ que produz uma função logística que **melhor se ajusta aos dados**.\n",
    "\n",
    "Para ilustrar este ponto novamente, vamos produzir a seguir algumas das infinitas funções de $\\mathcal{H}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:47:44.221057Z",
     "start_time": "2022-05-02T21:47:44.148101Z"
    }
   },
   "outputs": [],
   "source": [
    "def hip_lin(x, b0, b1):\n",
    "    \n",
    "    return b0 + b1*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:47:44.407936Z",
     "start_time": "2022-05-02T21:47:44.225055Z"
    }
   },
   "outputs": [],
   "source": [
    "def sig(x):\n",
    "    \n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:47:44.891524Z",
     "start_time": "2022-05-02T21:47:44.410934Z"
    }
   },
   "outputs": [],
   "source": [
    "b0 = 1\n",
    "b1 = 2\n",
    "\n",
    "x = np.linspace(-10, 10, 1000)\n",
    "\n",
    "y_lin = hip_lin(x, b0, b1)\n",
    "\n",
    "y_sig = sig(y_lin)\n",
    "\n",
    "plt.plot(x, y_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:47:45.097409Z",
     "start_time": "2022-05-02T21:47:44.893522Z"
    }
   },
   "outputs": [],
   "source": [
    "b0 = 1\n",
    "b1 = 2\n",
    "\n",
    "x = np.linspace(-10, 10, 1000)\n",
    "\n",
    "# composição de funções! \n",
    "y = sig(hip_lin(x, b0, b1))\n",
    "\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:47:45.382244Z",
     "start_time": "2022-05-02T21:47:45.099405Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-50, 50, 1000)\n",
    "\n",
    "b0 = 1\n",
    "b1_list = [0, -0.1, -0.5, 0.5, 0.1]\n",
    "\n",
    "for b1 in b1_list:\n",
    "\n",
    "    # composição de funções! \n",
    "    y = sig(hip_lin(x, b0, b1))\n",
    "\n",
    "    plt.plot(x, y, label=f\"b1={b1}\")\n",
    "    \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:47:45.589126Z",
     "start_time": "2022-05-02T21:47:45.384245Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-10, 10, 1000)\n",
    "\n",
    "b1 = 1\n",
    "b0_list = [0, -2, -0.5, 0.5, 2]\n",
    "\n",
    "for b0 in b0_list:\n",
    "\n",
    "    # composição de funções! \n",
    "    y = sig(hip_lin(x, b0, b1))\n",
    "\n",
    "    plt.plot(x, y, label=f\"b0={b0}\")\n",
    "    \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a biblioteca [ipywidgets](https://ipywidgets.readthedocs.io/en/latest/) podemos fazer plots interativos super legais!\n",
    "\n",
    "Valeu Marcelo e Alexandre pela ótima dica!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:47:45.605250Z",
     "start_time": "2022-05-02T21:47:45.595123Z"
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "def reg_lod_widget(b1=1, b0=1):\n",
    "    \n",
    "    # composição de funções! \n",
    "    y = sig(hip_lin(x, b0, b1))\n",
    "\n",
    "    plt.plot(x, y, label=f\"$b_0$={b0} | $b_1$={b1}\")\n",
    "    \n",
    "    plt.legend()\n",
    "    \n",
    "    plt.ylim(-0.25, 1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:47:46.472625Z",
     "start_time": "2022-05-02T21:47:45.608194Z"
    }
   },
   "outputs": [],
   "source": [
    "widgets.interact(reg_lod_widget, b0=(-2, 2, 0.1), b1=(-2, 2, 0.1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "### Função de perda e algoritmo de aprendizagem\n",
    "\n",
    "A função de perda para a regressão logística é a famosa [binary cross-entropy](https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a), também conhecida como [log loss](https://developers.google.com/machine-learning/crash-course/logistic-regression/model-training)\n",
    "\n",
    "Esta função será de enorme importância no estudo de **redes neurais**.\n",
    "\n",
    "As principais implementações do algoritmo de aprendizagem da regressão logística se baseia no [método de máxima verossimilhança](https://pt.wikipedia.org/wiki/M%C3%A1xima_verossimilhan%C3%A7a). \n",
    "\n",
    "Para maiores detalhes sobre o algoritmo de aprendizagem, veja [este vídeo](https://youtu.be/yIYKR4sgzI8) e [esta série de vídeos](https://youtu.be/vN5cNN2-HWE), do ótimo canal StatQuest!\n",
    "\n",
    "\n",
    "_________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos analisar um pouco mais nosso dataset de marketing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:47:46.549567Z",
     "start_time": "2022-05-02T21:47:46.477613Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui novamente, vamos considerar apenas as colunas numéricas como features. \n",
    "\n",
    "Sigamos com o train-test split!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:47:46.612531Z",
     "start_time": "2022-05-02T21:47:46.552568Z"
    }
   },
   "outputs": [],
   "source": [
    "df_model = df.select_dtypes(include=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:47:46.691487Z",
     "start_time": "2022-05-02T21:47:46.615530Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df_model.drop(columns=\"Clicked on Ad\")\n",
    "y = df_model[\"Clicked on Ad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:47:47.179647Z",
     "start_time": "2022-05-02T21:47:46.695487Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:47:48.882964Z",
     "start_time": "2022-05-02T21:47:47.182644Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in X_train:\n",
    "    \n",
    "    sns.histplot(data=X_train, x=col, kde=True)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando fizermos a EDA de um problema de classificação, é muito útil utilizar o target para analisar a **separabilidade** das classes! \n",
    "\n",
    "Para este fim, basta usarmos o argumento `hue` das funções do seaborn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:47:50.802594Z",
     "start_time": "2022-05-02T21:47:48.883354Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in X_train:\n",
    "    \n",
    "    sns.histplot(data=X_train, x=col, kde=True, hue=y_train)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O `pairplot` é uma ferramente legal para visualizarmos nossos dados projetados ao subspaço de cada par de features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:47:50.833788Z",
     "start_time": "2022-05-02T21:47:50.802594Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:05.844951Z",
     "start_time": "2022-05-02T21:47:50.841783Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data=pd.concat([X_train, y_train], axis=1), hue=\"Clicked on Ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como tínhamos comentado no início, nossos dados são muito bem separáveis!\n",
    "\n",
    "Isto favorece bastante a performance do nosso modelo. Mas, lembre-se, é bem raro encontrar casos assim na vida real! (É aí que devemos partir para métodos mais avançados, como SVM, árvores, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos começar a construir o modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:06.218102Z",
     "start_time": "2022-05-02T21:48:05.855946Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logit = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Modelo treinado!__\n",
    "\n",
    "$$f_{H, \\vec{b}}(\\vec{x}) = P(y=1 | \\vec{x}) = \\frac{1}{1 + e^{-(b_0 + b_1 x_1 + \\cdots + b_p x_p)}}$$\n",
    "\n",
    "Vamos ver os parâmetros do modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:06.234095Z",
     "start_time": "2022-05-02T21:48:06.221101Z"
    }
   },
   "outputs": [],
   "source": [
    "logit.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:06.612878Z",
     "start_time": "2022-05-02T21:48:06.238093Z"
    }
   },
   "outputs": [],
   "source": [
    "logit.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:06.973673Z",
     "start_time": "2022-05-02T21:48:06.616876Z"
    }
   },
   "outputs": [],
   "source": [
    "logit.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:07.273500Z",
     "start_time": "2022-05-02T21:48:06.981684Z"
    }
   },
   "outputs": [],
   "source": [
    "logit.coef_[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembre-se que, diferentemente da regressão linear, devido ao fato da função logística ser uma exponencial, a variação de $P(x)$ depende de x, e não apenas dos coeficientes! Então, a interpretação dos coeficientes não é tão imediata. \n",
    "\n",
    "Mas, os sinais carregam significado. Para um coeficiente:\n",
    "- positivo ($b_i > 0$), temos que um aumento em x levará a um aumento de $P(x)$;\n",
    "- negativo ($b_i < 0$), temos que um aumento em x levará a uma diminuição de $P(x)$\n",
    "\n",
    "Mas, a variacão de $P(x)$ em si, depende do valor de x!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Agora que o modelo está treinado, vamos avaliá-lo!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "_____\n",
    "_____\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:07.634295Z",
     "start_time": "2022-05-02T21:48:07.276500Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:07.759227Z",
     "start_time": "2022-05-02T21:48:07.637295Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:07.964107Z",
     "start_time": "2022-05-02T21:48:07.763224Z"
    }
   },
   "outputs": [],
   "source": [
    "logit.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além dos coeficientes do modelo, algo muito interessante que a classe do sklearn proporciona é o método `predict_proba()`\n",
    "\n",
    "Esse método retorna exatamente qual é a **probabilidade modelada pelo logit**, isto é, $P(y=1 | \\vec{x})$.\n",
    "\n",
    "Isso pode ser muito útil, pois assim conseguimos **mudar qual é o cutoff de escolha de classe** para ser algo diferente de 0.5!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:08.215074Z",
     "start_time": "2022-05-02T21:48:07.968106Z"
    }
   },
   "outputs": [],
   "source": [
    "logit.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:08.514796Z",
     "start_time": "2022-05-02T21:48:08.218966Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "proba_1 = logit.predict_proba(X_test)[:, 1]\n",
    "\n",
    "proba_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:08.764651Z",
     "start_time": "2022-05-02T21:48:08.517793Z"
    }
   },
   "outputs": [],
   "source": [
    "cutoff = 0.1\n",
    "\n",
    "np.where(proba_1 >= cutoff, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:08.937552Z",
     "start_time": "2022-05-02T21:48:08.768651Z"
    }
   },
   "outputs": [],
   "source": [
    "cutoff = 0.9\n",
    "\n",
    "np.where(proba_1 >= cutoff, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Métricas de performance para problemas de classificação\n",
    "\n",
    "Após treinar o modelo, como podemos avaliar sua performance?\n",
    "\n",
    "No caso de problemas de classificação, existem **métricas específicas**, e também um importante conceito chamado de **Matriz de Confusão**.\n",
    "\n",
    "A **matriz de confusão** leva em consideração as **classes preditas** e as **classes verdadeiras** da base de **teste**, e contabiliza a performance do modelo:\n",
    "\n",
    "<img src=https://diegonogare.net/wp-content/uploads/2020/04/matrizConfusao-600x381.png height=\"400\" width=\"400\">\n",
    "\n",
    "Note que a diagonal principal são as observações que o modelo acertou! Temos:\n",
    "\n",
    "- Verdadeiros Positivos (VP): classificação correta da classe positivo;\n",
    "- Verdadeiros Negativos (VN): classificação correta da classe negativo;\n",
    "- Falsos Positivos (FP, erro tipo I): correto: negativo. Previsto: positivo.\n",
    "- Falsos Negativos (FN, erro tipo II): correto: positivo. Previsto: negativo.\n",
    "\n",
    "Um jeito fácil de lembrar os tipos de erros:\n",
    "\n",
    "<img src=\"https://i.pinimg.com/originals/f6/9b/11/f69b111014ef466fe541a393346d2c3a.jpg\" height=\"400\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **IMPORTANTE**: dependendo da implementação/referência, a ordem das linhas/colunas pode mudar, então se atente a isso quando for interpretar a matriz de confusão!\n",
    "\n",
    "No Sklearn, a convenção é a seguinte:\n",
    "\n",
    "<img src=\"https://static.packt-cdn.com/products/9781838555078/graphics/C13314_06_05.jpg\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além disso, temos as seguintes métricas numéricas de avaliação:\n",
    "\n",
    "- Acurácia (Accuracy): porcentagem de classificações CORRETAS do modelo;\n",
    "\n",
    "- Precisão (Precision): das respostas retornadas, quantas são relevantes? -- é a razão entre verdadeiros positivos e o  número de **preditos positivos**, isto é, positivos quanto à **label predita pelo modelo**.\n",
    "\n",
    "- Revocação/Sensibilidade (Recall/Sensitivity): das respostas relevantes, quantas são retornadas? -- é a razão entre verdadeiros positivos e o  número de **verdadeiramente positivos**, isto é, positivos quanto à **label real**.\n",
    "\n",
    "- F1-Score: média harmônica de precision e recall.\n",
    "\n",
    "Descrição da imagem: \n",
    "\n",
    "> tudo o que tá no lado esquerdo é a classe real positiva (y = 1); do lado direito, real negativa (y = 0);\n",
    "\n",
    "> tudo o que tá dentro do circulo predita positiva ($\\hat{y} = 1$); fora do circulo, predita negativa ($\\hat{y} =0$)\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/1200px-Precisionrecall.svg.png\" width=400>\n",
    "\n",
    "Devido ao <a href=\"https://medium.com/opex-analytics/why-you-need-to-understand-the-trade-off-between-precision-and-recall-525a33919942\">tradeoff entre precision e recall</a>, uma métrica que em muitos casos é interessante de ser otimizada é o F1! \n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1080/1*t1vf-ofJrJqtmam0KSn3EQ.png\" width=500>\n",
    "\n",
    "Adiante, veremos como calcular a matriz de confusão e as métricas acima para problemas de classificação!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um ponto muito importante é que o método `predict()` se utiliza do cutoff igual a 0.5 para tomar a decisão! Veremos mais detalhes sobre isso mais a frente. Por enquanto, vamos seguir com a avaliação do modelo com este cutoff padrão!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:09.204399Z",
     "start_time": "2022-05-02T21:48:08.947549Z"
    }
   },
   "outputs": [],
   "source": [
    "# y_pred = logit.predict(X_test)\n",
    "\n",
    "proba_1 = logit.predict_proba(X_test)[:, 1]\n",
    "cutoff = 0.5\n",
    "y_pred = np.where(proba_1 >= cutoff, 1, 0)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos no passo 2, em problemas de classificação é muito comum utilizarmos a **matriz de confusão** e as **métricas de classificação** para avaliar nossos modelos.\n",
    "\n",
    "Dado isso, o sklearn já disponibilica estas funcionalidades! Vejamos algumas delas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:09.408284Z",
     "start_time": "2022-05-02T21:48:09.207398Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:10.250806Z",
     "start_time": "2022-05-02T21:48:09.411282Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:10.925433Z",
     "start_time": "2022-05-02T21:48:10.253802Z"
    }
   },
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, normalize=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:10.957409Z",
     "start_time": "2022-05-02T21:48:10.929425Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:11.128310Z",
     "start_time": "2022-05-02T21:48:10.961407Z"
    }
   },
   "outputs": [],
   "source": [
    "cr_dict = classification_report(y_test, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:11.270230Z",
     "start_time": "2022-05-02T21:48:11.131310Z"
    }
   },
   "outputs": [],
   "source": [
    "cr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:11.502889Z",
     "start_time": "2022-05-02T21:48:11.272229Z"
    }
   },
   "outputs": [],
   "source": [
    "cr_dict[\"1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:11.660580Z",
     "start_time": "2022-05-02T21:48:11.504904Z"
    }
   },
   "outputs": [],
   "source": [
    "cr_dict[\"1\"][\"precision\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:11.801502Z",
     "start_time": "2022-05-02T21:48:11.663582Z"
    }
   },
   "outputs": [],
   "source": [
    "cr_dict[\"weighted avg\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme esperado, nosso modelo está muito bom! Um f1-score tão alto na vida real é algo notável!\n",
    "\n",
    "Isso se deve à grande separabilidade dos nossos dados!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:11.957413Z",
     "start_time": "2022-05-02T21:48:11.805499Z"
    }
   },
   "outputs": [],
   "source": [
    "def clf_metrics(modelo, X, y, cutoff=0.5, label_metrica=\"\", print_plot=True):\n",
    "    \n",
    "    proba_1 = logit.predict_proba(X)[:, 1]\n",
    "    y_pred = np.where(proba_1 >= cutoff, 1, 0)\n",
    "    \n",
    "    if print_plot:\n",
    "        \n",
    "        print(f\"Métricas de avaliação de {label_metrica}\")\n",
    "    \n",
    "        ConfusionMatrixDisplay.from_predictions(y, y_pred)\n",
    "        plt.show()\n",
    "    \n",
    "        print(classification_report(y, y_pred))\n",
    "    \n",
    "    return classification_report(y, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:12.320203Z",
     "start_time": "2022-05-02T21:48:11.961410Z"
    }
   },
   "outputs": [],
   "source": [
    "cr_train = clf_metrics(logit, X_train, y_train, label_metrica=\"treino\", cutoff=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T22:23:21.315544Z",
     "start_time": "2022-05-02T22:23:21.241587Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:12.739964Z",
     "start_time": "2022-05-02T21:48:12.327200Z"
    }
   },
   "outputs": [],
   "source": [
    "cr_test = clf_metrics(logit, X_test, y_test, label_metrica=\"teste\", cutoff=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:12.755955Z",
     "start_time": "2022-05-02T21:48:12.744962Z"
    }
   },
   "outputs": [],
   "source": [
    "cr_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos avaliar diferentes cutoffs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:13.208679Z",
     "start_time": "2022-05-02T21:48:12.759953Z"
    }
   },
   "outputs": [],
   "source": [
    "logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pra entender o código abaixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:13.690344Z",
     "start_time": "2022-05-02T21:48:13.211688Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(cr_test)\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:14.032634Z",
     "start_time": "2022-05-02T21:48:13.692342Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(cr_train)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:14.455678Z",
     "start_time": "2022-05-02T21:48:14.035633Z"
    }
   },
   "outputs": [],
   "source": [
    "results_train = {\"cutoff\" : []}\n",
    "\n",
    "# o [:-1] é pra não trazer o \"support\" (se quiser trazer, é só tirar isso)\n",
    "for idx in df_train.index[:-1]:\n",
    "    \n",
    "    for col in df_train:\n",
    "        \n",
    "        results_train[f\"{idx}_{col}\"] = []\n",
    "        \n",
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:15.094513Z",
     "start_time": "2022-05-02T21:48:14.457603Z"
    }
   },
   "outputs": [],
   "source": [
    "results_test = {\"cutoff\" : []}\n",
    "\n",
    "for idx in df_test.index[:-1]:\n",
    "    \n",
    "    for col in df_test:\n",
    "        \n",
    "        results_test[f\"{idx}_{col}\"] = []\n",
    "        \n",
    "results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:19.512716Z",
     "start_time": "2022-05-02T21:48:15.097516Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cutoff_list = np.arange(0.1, 1, 0.05)\n",
    "\n",
    "for cutoff in cutoff_list:\n",
    "    \n",
    "    print()\n",
    "    print(\"#\"*80)\n",
    "    print(f\"Modelo logit com cutoff = {cutoff}\".center(80))\n",
    "    print(\"#\"*80)\n",
    "    print()\n",
    "    \n",
    "    # ============================================\n",
    "    \n",
    "    cr_train = clf_metrics(logit, X_train, y_train, label_metrica=\"treino\", cutoff=cutoff, print_plot=False)\n",
    "    df_cr_train = pd.DataFrame(cr_train)\n",
    "\n",
    "    results_train[\"cutoff\"].append(cutoff)\n",
    "\n",
    "    for idx in df_cr_train.index[:-1]:\n",
    "\n",
    "        for col in df_cr_train:\n",
    "\n",
    "            results_train[f\"{idx}_{col}\"].append(df_cr_train.loc[idx, col])\n",
    "            \n",
    "    # ============================================\n",
    "    \n",
    "    cr_test = clf_metrics(logit, X_test, y_test, label_metrica=\"teste\", cutoff=cutoff)\n",
    "    df_cr_test = pd.DataFrame(cr_test)\n",
    "    \n",
    "    results_test[\"cutoff\"].append(cutoff)\n",
    "    \n",
    "    for idx in df_cr_test.index[:-1]:\n",
    "\n",
    "        for col in df_cr_test:\n",
    "\n",
    "            results_test[f\"{idx}_{col}\"].append(df_cr_test.loc[idx, col])\n",
    "    \n",
    "    # ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:19.543947Z",
     "start_time": "2022-05-02T21:48:19.512716Z"
    }
   },
   "outputs": [],
   "source": [
    "df_results_train = pd.DataFrame(results_train)\n",
    "\n",
    "df_results_train.sort_values(\"precision_1\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:19.743772Z",
     "start_time": "2022-05-02T21:48:19.546652Z"
    }
   },
   "outputs": [],
   "source": [
    "df_results_test = pd.DataFrame(results_test)\n",
    "\n",
    "df_results_test.sort_values(\"precision_1\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativamente, podemos fazer como abaixo (adaptado da sugestão do Marcelo, créditos a ele!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:24.020941Z",
     "start_time": "2022-05-02T21:48:19.746768Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# começamos com dois dfs vazios, e vamos preenchendo abaixo\n",
    "# (com os concats)\n",
    "df_results_train = pd.DataFrame()\n",
    "df_results_test = pd.DataFrame()\n",
    "\n",
    "cutoff_list = np.arange(0.1, 1, 0.05)\n",
    "\n",
    "for cutoff in cutoff_list:\n",
    "    \n",
    "    print()\n",
    "    print(\"#\"*80)\n",
    "    print(f\"Modelo logit com cutoff = {cutoff}\".center(80))\n",
    "    print(\"#\"*80)\n",
    "    print()\n",
    "    \n",
    "    # ============================================\n",
    "    \n",
    "    cr_train = clf_metrics(logit, X_train, y_train, label_metrica=\"treino\", cutoff=cutoff, print_plot=False)\n",
    "    df_cr_train = pd.DataFrame(cr_train)\n",
    "\n",
    "    # o .iloc[:-1, :] é pra excluir o \"support\" (pode trazer tb caso queira)\n",
    "    df_melt = df_cr_train.iloc[:-1, :].reset_index(drop=False).melt(id_vars='index', var_name=\"type\")\n",
    "    df_melt['cutoff'] = cutoff\n",
    "\n",
    "    # corrigindo os dados de acurácia\n",
    "    accuracy = df_melt.query(\"type == 'accuracy'\").copy()\n",
    "    accuracy[\"index\"] = \"accuracy\"\n",
    "\n",
    "    df_melt = df_melt.drop(index=accuracy.index)\n",
    "    df_melt = pd.concat([df_melt, accuracy.iloc[[0], :]]).reset_index(drop=False)\n",
    "\n",
    "    # pivotando\n",
    "    df_pivot = df_melt.pivot(columns=['type', 'index'], values='value', index='cutoff')\n",
    "    \n",
    "    df_results_train = pd.concat([df_results_train, df_pivot])\n",
    "            \n",
    "    # ============================================\n",
    "    \n",
    "    cr_test = clf_metrics(logit, X_test, y_test, label_metrica=\"teste\", cutoff=cutoff)\n",
    "    df_cr_test = pd.DataFrame(cr_test)\n",
    "    \n",
    "    # o .iloc[:-1, :] é pra excluir o \"support\" (pode trazer tb caso queira)\n",
    "    df_melt = df_cr_test.iloc[:-1, :].reset_index(drop=False).melt(id_vars='index', var_name=\"type\")\n",
    "    df_melt['cutoff'] = cutoff\n",
    "\n",
    "    # corrigindo os dados de acurácia\n",
    "    accuracy = df_melt.query(\"type == 'accuracy'\").copy()\n",
    "    accuracy[\"index\"] = \"accuracy\"\n",
    "\n",
    "    df_melt = df_melt.drop(index=accuracy.index)\n",
    "    df_melt = pd.concat([df_melt, accuracy.iloc[[0], :]]).reset_index(drop=False)\n",
    "\n",
    "    # pivotando\n",
    "    df_pivot = df_melt.pivot(columns=['type', 'index'], values='value', index='cutoff')\n",
    "    \n",
    "    df_results_test = pd.concat([df_results_test, df_pivot])\n",
    "    \n",
    "    # ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:24.067817Z",
     "start_time": "2022-05-02T21:48:24.020941Z"
    }
   },
   "outputs": [],
   "source": [
    "df_results_train\n",
    "\n",
    "df_results_train.sort_values(('1', 'precision'), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:48:24.342912Z",
     "start_time": "2022-05-02T21:48:24.070779Z"
    }
   },
   "outputs": [],
   "source": [
    "df_results_test\n",
    "\n",
    "df_results_test.sort_values(('1', 'precision'), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T23:04:33.109481Z",
     "start_time": "2022-05-02T23:04:33.067505Z"
    }
   },
   "outputs": [],
   "source": [
    "df_results_test\n",
    "\n",
    "df_results_test.sort_values(('weighted avg', 'f1-score'), ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "\n",
    "### Tradeoff precision/recall\n",
    "\n",
    "Conforme é possível ver acima, claramente há um **tradeoff** entre precision e recall conforme variamos o cutoff. Isso faz total sentido, dado que estas métricas representam!\n",
    "\n",
    "Podemos visualizar este tradeoff facilmente com o sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T22:50:39.098264Z",
     "start_time": "2022-05-02T22:50:39.087271Z"
    }
   },
   "outputs": [],
   "source": [
    "y_proba_1 = logit.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T22:51:25.479125Z",
     "start_time": "2022-05-02T22:51:25.467134Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precisions, recalls, cutoffs = precision_recall_curve(y_test, y_proba_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para plotar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T22:53:37.336189Z",
     "start_time": "2022-05-02T22:53:37.073338Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.title(\"Precision-recall tradeoff\")\n",
    "\n",
    "plt.plot(recalls, precisions)\n",
    "\n",
    "plt.xlabel(\"Recalls\")\n",
    "plt.ylabel(\"Precisons\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T23:08:26.455440Z",
     "start_time": "2022-05-02T23:08:26.114924Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "PrecisionRecallDisplay.from_predictions(y_test, y_proba_1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou, então:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T22:55:38.392881Z",
     "start_time": "2022-05-02T22:55:38.371381Z"
    }
   },
   "outputs": [],
   "source": [
    "precisions.shape, recalls.shape, cutoffs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T23:00:23.774515Z",
     "start_time": "2022-05-02T23:00:23.756543Z"
    }
   },
   "outputs": [],
   "source": [
    "np.where(precisions == recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T23:00:24.887269Z",
     "start_time": "2022-05-02T23:00:24.874272Z"
    }
   },
   "outputs": [],
   "source": [
    "cutoffs[np.where(precisions == recalls)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T23:01:08.924230Z",
     "start_time": "2022-05-02T23:01:08.658381Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.title(\"Precision-recall tradeoff\")\n",
    "\n",
    "plt.plot(cutoffs, precisions[:-1], label=\"precision\")\n",
    "plt.plot(cutoffs, recalls[:-1], label=\"recall\")\n",
    "\n",
    "plt.xlabel(\"Cutoffs\")\n",
    "\n",
    "ponto_de_encontro = cutoffs[np.where(precisions == recalls)]\n",
    "plt.axvline(x=ponto_de_encontro, ls=\":\", color=\"k\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "\n",
    "### Curva ROC e AUC-ROC (AUROC)\n",
    "\n",
    "Veremos agora uma outra métrica de avaliação de modelos de classificação que é intimamente ligada com os diferentes thresholds possíveis -- a **AUC (Area Under The Curve) da curva ROC (Receiver Operating Characteristics)**, por vezes chamada de **AUROC (Area Under the Receiver Operating Characteristics)**\n",
    "\n",
    "A curva **ROC é uma curva de probabilidade**, sendo que **AUC é a área sob a curva**, representando **o grau de separabilidade atingido pelo modelo**.\n",
    "\n",
    "Ou seja, esta medida nos diz **o quanto o modelo é capaz de distinguir entre duas classes**.\n",
    "\n",
    "A curva ROC é construída com a **taxa de falsos positivos** no eixo x, e a **taxa de verdadeiros positivos** no eixo y, para diferentes **thresholds de classificação**:\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1175/1*2nd7NTEBosPakccmLVWy9A.png\" width=500>\n",
    "\n",
    "O valor do AUC-ROC sempre estará **entre 0 e 1**, sendo que **quanto mais próximo de 1, melhor o modelo**.\n",
    "\n",
    "> Valores de AUC-ROC maiores que 0.5 (mais próximos de 1) significam que o modelo tem uma **taxa de verdadeiros positivos maior que a taxa de falsos positivos**, ou seja, o modelo está acertando mais!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quanto **mais próximo de 0** (para valores abaixo de 0.5), teremos um modelo que faz um bom trabalho em separar as classes, mas as classifica erroneamente.\n",
    "\n",
    "E, quanto **mas próximo de 0.5**, pior é o modelo em separar as classes: seria um modelo que simplesmente chuta aleatoriamente ora a classe 0, ora a classe 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja as imagens a seguir para uma ilustração:\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/528/1*Uu-t4pOotRQFoyrfqEvIEg.png\" width=500>\n",
    "\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/507/1*yF8hvKR9eNfqqej2JnVKzg.png\" width=500>\n",
    "\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/430/1*iLW_BrJZRI0UZSflfMrmZQ.png\" width=500>\n",
    "\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/556/1*aUZ7H-Lw74KSucoLlj1pgw.png\" width=500>\n",
    "\n",
    "Ao olhar para a curva em si, temos a seguinte interpretação:\n",
    "\n",
    "<img src=\"https://i.ytimg.com/vi/J9l8J1MeCbY/hqdefault.jpg\" width=400>\n",
    "\n",
    "Para aprender mais sobre a construção da curva ROC, sugiro [este StatQuest!](https://www.youtube.com/watch?v=4jRBRDbJemM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T23:21:21.778441Z",
     "start_time": "2022-05-02T23:21:21.757454Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, cutoffs = roc_curve(y_test, y_proba_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para plotar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T23:22:26.191635Z",
     "start_time": "2022-05-02T23:22:25.871802Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.title(\"ROC curve\")\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "\n",
    "x = np.linspace(0, 1, 2)\n",
    "plt.plot(x, x, color=\"k\", ls=\":\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T23:26:48.355808Z",
     "start_time": "2022-05-02T23:26:48.092957Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_test, y_proba_1)\n",
    "\n",
    "x = np.linspace(0, 1, 2)\n",
    "plt.plot(x, x, color=\"k\", ls=\":\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, pra calcular o AUC-ROC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T23:24:02.850736Z",
     "start_time": "2022-05-02T23:24:02.800768Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, y_proba_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E se tivermos uma classificação multiclasse?\n",
    "\n",
    "Há problemas em que temos um problema de **classificação multiclasse**, pois há mais do que duas classes a serem preditas.\n",
    "\n",
    "<img src=\"https://utkuufuk.com/2018/06/03/one-vs-all-classification/one-vs-all.png\">\n",
    "\n",
    "Boa noitícia: o operacional de construção e avaliação do modelo com o sklearn muda em absolutamente **nada**.\n",
    "\n",
    "No entanto, conceitualmente, há algumas mudanças: a rigor, o modelo passa a se chamar **regresão logística MULTINOMIAL**, cujo processo de classificação é dado pela função **softmax**:\n",
    "\n",
    "<img src=\"https://i.stack.imgur.com/YLeRi.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para quem quiser saber mais sobre o \"logit score\", [clique aqui](https://stats.stackexchange.com/questions/329857/what-is-the-difference-between-decision-function-predict-proba-and-predict-fun).\n",
    "\n",
    "Essencialmente, esse é o valor do termo linear usado como argumento da sigmoide, isto é, $z(x) = b_0 + b_1 x_1 + \\cdots + b_p x_p$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível capturar o score pelo método `decision_function`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T23:46:37.308675Z",
     "start_time": "2022-05-02T23:46:37.297685Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T23:46:53.848028Z",
     "start_time": "2022-05-02T23:46:53.838035Z"
    }
   },
   "outputs": [],
   "source": [
    "logit.intercept_, logit.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T23:47:29.564520Z",
     "start_time": "2022-05-02T23:47:29.546922Z"
    }
   },
   "outputs": [],
   "source": [
    "logit.intercept_ + (logit.coef_[0]*X_test.iloc[0].values).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T23:43:56.980530Z",
     "start_time": "2022-05-02T23:43:56.947550Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logit.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T23:47:58.902154Z",
     "start_time": "2022-05-02T23:47:58.890159Z"
    }
   },
   "outputs": [],
   "source": [
    "1/(1 + np.exp(-(logit.intercept_ + (logit.coef_[0]*X_test.iloc[0].values).sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T23:48:09.711980Z",
     "start_time": "2022-05-02T23:48:09.688997Z"
    }
   },
   "outputs": [],
   "source": [
    "logit.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na lista de exercícios, vocês trabalharão com um problema multiclasse (dataset `iris`). Não deixe de explorar mais a fundo o `decision_function` neste dataset, para entender seu funcionamento!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "249.667px",
    "width": "359.667px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
